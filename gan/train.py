import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torch.utils.data import DataLoader
from tqdm import tqdm
import os
from model import PatchGANDiscriminator 
import torchvision.transforms as transforms 
from UNet import UNet # Assuming your U-Net model is in a file named U-Net.py
# --- Assuming your data_loader.py and U-Net model are defined ---
from data_loader import OxfordPetInpaintingDataset, transform # Your existing data loader
# Your U-Net class definition should be here or imported
# For this example, let's assume UNet class is defined as in your previous script.
# (Copy UNetConvBlock, Down, Up, OutConv, UNet class definitions here if not imported)
# --- Placeholder for U-Net (Generator G) ---

# --- End of U-Net Placeholder ---


# --- Configuration ---
IMG_SIZE = 128 # Keep consistent with your dataset
BATCH_SIZE = 8  # GANs often require smaller batch sizes
DATA_DIR = '../data_pets'
NUM_EPOCHS = 100 # Start with this, GANs can take longer
LR_G = 1e-4     # Learning rate for generator
LR_D = 1e-4     # Learning rate for discriminator
BETA1 = 0.5     # Adam optimizer beta1
LAMBDA_L1 = 100.0 # Weight for L1 reconstruction loss
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
OUTPUT_DIR = './gan_inpainting_results'
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# --- DataLoaders ---
train_dataset = OxfordPetInpaintingDataset(
    root_dir=DATA_DIR, split='trainval', transform=transform, download=True
)
train_dataloader = DataLoader(
    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0
)
# (You can also have a val_dataloader for periodic evaluation)

# --- Initialize Generator (G) and Discriminator (D) ---
netG = UNet(n_channels_in=3, n_channels_out=3).to(DEVICE)
# For inpainting, the discriminator usually sees the inpainted image OR a real image.
# So, input_channels for D is 3 (for the image channels).
netD = PatchGANDiscriminator(input_channels=3).to(DEVICE)

# --- Loss Functions ---
criterion_GAN = nn.BCEWithLogitsLoss() # Adversarial loss
criterion_L1 = nn.L1Loss()             # Reconstruction loss

# --- Optimizers ---
optimizerG = optim.Adam(netG.parameters(), lr=LR_G, betas=(BETA1, 0.999))
optimizerD = optim.Adam(netD.parameters(), lr=LR_D, betas=(BETA1, 0.999))

# --- Utility to save sample images ---
def denormalize_imagenet(tensor): # Assuming ImageNet stats for normalization
    denorm_transform = transforms.Compose([
        transforms.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225]),
        transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1., 1., 1.]),])
    return torch.clamp(denorm_transform(tensor), 0, 1)

# --- Training Loop ---
if __name__ == '__main__': # Important for multiprocessing if num_workers > 0
    if DEVICE.type == 'cuda' and os.name == 'nt': # Windows specific check for freeze_support
        from multiprocessing import freeze_support
        freeze_support()

    print(f"Starting GAN training on {DEVICE}...")
    for epoch in range(NUM_EPOCHS):
        netG.train()
        netD.train()
        total_loss_g = 0
        total_loss_d = 0

        progress_bar = tqdm(train_dataloader, desc=f"Epoch {epoch+1}/{NUM_EPOCHS}")
        for i, (masked_images, original_images, masks) in enumerate(progress_bar):
            masked_images = masked_images.to(DEVICE)     # Input to G
            original_images = original_images.to(DEVICE) # Ground truth / Real images for D
            # masks are not directly used in this basic GAN loop but available from dataloader

            # --------------------
            # Train Discriminator (D)
            # --------------------
            optimizerD.zero_grad()

            # Real images
            real_output_D = netD(original_images)
            # Target for real images is a tensor of 1s (real)
            # The shape of real_output_D depends on PatchGAN architecture (e.g., B, 1, H/16, W/16)
            target_real = torch.ones_like(real_output_D, device=DEVICE)
            loss_D_real = criterion_GAN(real_output_D, target_real)

            # Fake images (generated by G)
            # Detach fake_images so G's gradients are not computed during D's update
            fake_images = netG(masked_images).detach()
            fake_output_D = netD(fake_images)
            # Target for fake images is a tensor of 0s (fake)
            target_fake = torch.zeros_like(fake_output_D, device=DEVICE)
            loss_D_fake = criterion_GAN(fake_output_D, target_fake)

            # Combined discriminator loss
            loss_D = (loss_D_real + loss_D_fake) * 0.5 # Average
            loss_D.backward()
            optimizerD.step()
            total_loss_d += loss_D.item()

            # --------------------
            # Train Generator (G)
            # --------------------
            optimizerG.zero_grad()

            # G generates fake images
            generated_images = netG(masked_images)

            # G wants D to think the fake images are real
            output_G_fake_for_D = netD(generated_images)
            loss_G_GAN = criterion_GAN(output_G_fake_for_D, target_real) # G tries to make D output 1s

            # Reconstruction loss (L1)
            loss_G_L1 = criterion_L1(generated_images, original_images) * LAMBDA_L1

            # Combined generator loss
            loss_G = loss_G_GAN + loss_G_L1
            loss_G.backward()
            optimizerG.step()
            total_loss_g += loss_G.item()

            progress_bar.set_postfix({
                'Loss_D': f"{loss_D.item():.4f}",
                'Loss_G': f"{loss_G.item():.4f}",
                'Loss_G_GAN': f"{loss_G_GAN.item():.4f}",
                'Loss_G_L1': f"{loss_G_L1.item()/LAMBDA_L1:.4f}"
            })

        avg_loss_g = total_loss_g / len(train_dataloader)
        avg_loss_d = total_loss_d / len(train_dataloader)
        tqdm.write(f"Epoch [{epoch+1}/{NUM_EPOCHS}] Avg Loss_G: {avg_loss_g:.4f}, Avg Loss_D: {avg_loss_d:.4f}")

        # Save some sample images periodically
        if (epoch + 1) % 5 == 0 or epoch == NUM_EPOCHS - 1:
            with torch.no_grad():
                netG.eval() # Set G to evaluation mode for inference
                sample_masked = masked_images[0:min(4, BATCH_SIZE)].cpu()
                sample_generated = netG(masked_images[0:min(4, BATCH_SIZE)]).cpu()
                sample_original = original_images[0:min(4, BATCH_SIZE)].cpu()

                # Denormalize for saving
                img_masked_denorm = denormalize_imagenet(sample_masked)
                img_generated_denorm = denormalize_imagenet(sample_generated)
                img_original_denorm = denormalize_imagenet(sample_original)

                # Create a comparison strip (Masked | Generated | Original)
                comparison_strip = []
                for k in range(img_masked_denorm.size(0)):
                    comparison_strip.extend([img_masked_denorm[k], img_generated_denorm[k], img_original_denorm[k]])
                
                grid = torchvision.utils.make_grid(comparison_strip, nrow=3, padding=5, normalize=False)
                torchvision.utils.save_image(grid, os.path.join(OUTPUT_DIR, f"epoch_{epoch+1}_sample.png"))
                tqdm.write(f"Saved sample images for epoch {epoch+1}")
                netG.train() # Back to train mode

    print("GAN Training Finished.")
    torch.save(netG.state_dict(), os.path.join(OUTPUT_DIR, 'netG_final.pth'))
    torch.save(netD.state_dict(), os.path.join(OUTPUT_DIR, 'netD_final.pth'))
    print(f"Final models saved to {OUTPUT_DIR}")